\pagestyle{empty}
\documentclass[11pt]{article}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{url}
\usepackage{graphicx, color}
\usepackage{amsmath}
%\usepackage[small,compact]{titlesec} 
%\usepackage[small,it]{caption}

\textwidth 6.5in
\headheight .1in
\topmargin -.2 in
\textheight 8.7in
\oddsidemargin 0in
\evensidemargin 1in

\begin{document} 

 \centerline{\Large \bf Blockmodels for Dynamic Network Data} 
 \medskip
\centerline{\bf Christopher DuBois}
 \bigskip

\section{Introduction}

Viewing interactions among entities as a network is an increasingly useful approach for studying  phenomenon ranging from people communicating online to protein interactions. One class of statistical models for network data use latent variables for each node to help capture unobserved heterogeneity.  For example, the stochastic blockmodel \cite{Nowicki2001} and its nonparametric extension \cite{Kemp2006} assume each node in the network belongs to some block (or cluster) and models the probability of edges between blocks.   Such approaches are especially useful for large-scale network data where higher order dependencies can cause models such as exponential random graph models to be too complex to fit.%\cite{Schweinberger2011}.

Network data, however, is often collected as a sequence of events occurring over time.   Recently several works have adapted models from survival analysis and event history analysis to provide continuous time models of network-based event data \cite{Butts2008,Brandes2009,Stadtfeld2010,Stadtfeld2011,Opsahl2011,Vu2011}.  These models are often semiparametric and allow one to specify the dependence of the process on the previous history of events.  In this way we can incorporate theories about the underlying processes and make predictions about future data conditioned on the past.

The above continuous time network models have two major drawbacks: 1) the entire network is assumed to have identical dynamics, and 2) the occurrence of any event can affect the rate at which any other event occurs.  Both aspects may be unrealistic.  Consider email communication in a small organization comprised of several teams.  Each team may have a different pattern for collaborating via email, and in many cases emails within one team will not affect emailing behavior within a separate team.

Borrowing from the intuition of stochastic blockmodels, we propose a hierarchical model of continuous time network data that learns latent clusters of nodes which share similar patterns of interaction with the rest of the network.  This combines a latent variable model with a local dependence model for modeling the event sequence among nearby nodes, a view which reveals its relationship to hierarchical extensions to latent position models \cite{Handcock2007} and exponential random graph models \cite{Schweinberger2011}.

\section{Model}

%Each interaction then has a set of periods $d \in D_{ij}$ each with a start time $a_d$, an end time $b_d$, and a rate $\lambda_d$.
Consider a nonhomogeneous Poisson process with  intensity $\lambda(t)$ that is piecewise constant with respect to a set of knots $\tau$.  We can then write the likelihood of $M$ events as
\begin{align}
\mathcal{L}(A|\theta) &= \prod_{m=1}^M \lambda(t_m) \exp\left\{ - \int_{0}^{t_M} \lambda(s)ds \right\} \\
&= \prod_{m=1}^M \lambda(t_m|\cdot) \prod_{k=1}^{|\tau|} \exp\left\{ - (\tau_{k} - \tau_{k-1}) \lambda(\tau_k) \right\}
\end{align}
\noindent where the $m$th event occurs at time $t_m$ and the intensity function $\lambda(t)$ is right continuous.
% \begin{align}
% \mathcal{L}(A|\theta) &= \prod_{m=1}^M \lambda_{i_m}(t_m|\cdot) \prod_{i \in \mathcal{R}}  \exp\left\{ - \int_{0}^{t_M} \lambda_{i}(\tau | \cdot)d\tau \right\} \\
% &= \prod_{m=1}^M \lambda_{i_m}(t_m|\cdot) \prod_{i \in \mathcal{R}} \prod_{v \in D_{i}} \exp\left\{ - (b_v - a_v) \lambda_{i}(b_v | \cdot ) \right\}
% \end{align}

In general, we may have different types of events that can occur.  Let  the \emph{risk set}  $\mathcal{R}$ be the set of possible events.   In the context of relational events occurring among $N$ nodes, for example, we let $\mathcal{R}$ include all dyads.\footnote{We exclude self-loops.}  Let each dyad $(i,j) \in \mathcal{R}$ have an intensity function $\lambda_{ij}(t|\cdot)$ which is piecewise constant.

For network data, we capture the notion that some events have no effect on the intensity of other events by assuming 1) each node $i$ belongs to some latent cluster $z_i$, and 2) each intensity function $\lambda_{ij}(t)$ may only change following an event involving a member of either $z_i$ or $z_j$.  See Figure \ref{fig:example}.

 In this case, the likelihood becomes

\begin{align}
\mathcal{L}(A|\theta) &= \prod_{m=1}^M \lambda_{i_m,j_m}(t_m|\cdot) \prod_{(i,j) \in \mathcal{R}} \prod_{k=1}^{|\boldsymbol{\tau}_{ij}|} \exp\{ - (\tau_{i,j,k} - \tau_{i,j,k-1}) \lambda_{ij}(\tau_{i,j,k} | \cdot) \} \\
&= \prod_{m=1}^M \lambda_{i_m,j_m}(t_m|\cdot) \prod_{k_1=1}^K \prod_{k_2=1}^K \prod_{(i,j) \in \mathcal{R_{k_1,k_2}}} \prod_{k=1}^{|\boldsymbol{\tau}_{ij}|} \exp\{ - (\tau_{i,j,k} - \tau_{i,j,k-1}) \lambda_{ij}(\tau_{i,j,k} | \cdot) \} \\
\end{align}


\begin{figure}
 \def\svgwidth{6in}
  \input{example.pdf_tex}
\caption{Illustration of the event data and the model assumptions.  Left: An event sequence among four nodes belonging to two clusters (circles and squares): (4,3) occurs at time $t_1$ and (2,1) occurs at time $t_2$.  Right: The intensity functions $\lambda_{21}(t)$ (solid) and $\lambda_{34}(t)$ (dotted).  Note $\lambda_{34}$ only can change when events occur involving a node in its cluster (square).}
\label{fig:example}
%\includegraphics[width=6in]{example}
\end{figure}

For a given dyad $(i,j)$ and time $t$ we may also have a vector of statistics $s_{ij}(t|A_t,\mathbf{z})$ that is a function of the previous history of events $A_t$ and the latent cluster assignments $z$.  We model the intensity functions via a log linear model conditioned on this information
\begin{align}
\log \lambda_{ij}(t | \mathcal{A}_t,\mathbf{z}) = \boldsymbol{\beta}_{z_i,z_j} \mathbf{s}_{ij}(t|\mathcal{A}_t,\mathbf{z}).
\end{align}
where for each pair of clusters $(z_i,z_j)$ we have a vector of parameters $\beta_{z_i,z_j}$ that corresponds to the covariate vector $s_{ij}(t|\cdot)$.  This is reminiscent of the stochastic blockmodel \cite{Nowicki2001, Kemp2006} which models the probability of a dyad as $p(y_{ij}) =\mbox{logit}^{-1}( \eta_{z_i,z_j})$ where $\eta_{z_i,z_j}$ is essentially a mixing rate between group $z_i$ and group $z_j$.  Here, however, we use a blockmodel structure facilitates the study of intra-group and inter-group dynamics via a continuous-time network model.

TODO: Discuss possible variations on the prior structure of $\beta$: 1. Enforce $\beta_{k,l} = \beta_{l,k}$. 2. Assume $\beta_{k,l,p} \sim \mbox{Normal}(\beta_p,\sigma_p^2)$. 3. Place other priors that provide different kinds of regularization. 

TODO: Discuss decision to condition on $z$ for covariate vector $s_{ij}$.

TODO: Discuss choice of $\log \lambda$ instead of just $\lambda$.

TODO: Discuss choice against time-varying effects.

TODO: Discuss if the semiparametric partial likelihood approach can be used in this framework.

\subsection{Model specification}

We include a similar set of statistics in $s_{ij}$ as used in \cite{Butts2008,Vuy2011}.
Note that the model assumptions imply $s_{ij}(t|\mathcal{A}_t,\mathbf{z}) = f(\mathcal{A}$.

Let $r$ be the last event from a $z_i$ node to a $z_j$ node, that is $r = \mbox{argmax}_{r \in \{1, \ldots, m\}}I(t_r < t, z_{i_r} = z_i, z_{j_r} = z_j)$

\begin{itemize}
\item In and out degree of sender and receiver
\item Reciprocity
\item Transitivity, triangle closure
\item Shared contacters, contactees
\end{itemize}

TODO: Would like things that combine shared contacts with recency. (i.e. Facebook-like terms.) 

\section{Inference}

We use Markov chain Monte Carlo to get samples from the posterior distribution of our parameters.  

\begin{enumerate}
\item For $i \in [1,N]$: Sample $z_i$ via Gibbs sampling.
\item For each pair $(k,k')$: Sample $\beta_{k,k'}$ via MH or HMC.
\end{enumerate}

To perform Gibbs sampling for a given cluster assignment $z_i$, we need to compute the likelihood for each possible assignment of $z_i$.  This involves recomputing each $\boldsymbol{\tau}$ and possibly each $\mathbf{s}_{ij}$ if it also depends on $\mathbf{z}$.

TODO: Decide how to handle label switching.  Schweinberger has an interesting approach I hadn't seen before for his hierarchical ERGMS.  Should look into that more closely...

\subsection*{Bookkeeping considerations}
%For each dyad, we need to keep track of the set of piecewise constant intervals $d_{ij}$.  For a given set of assignments $z$ we can compute these intervals $(a_v,b_v)$.

Recall we let intensities change whenever an event occurs involving a fellow cluster member.  Thus the vector $\boldsymbol{\tau}_{ij}$ of changepoints (or knots) is given by
$$\boldsymbol{\tau}_{ij} = \left\{ t_m: z_{i_m} = z_i \ \mbox{or} \ z_{j_m} = z_j, m=1,\ldots,M\right\}$$
Any time we update we change node $k$'s cluster assignment from $a$ to $b$, the change point vectors for any nodes in $a$ and $b$ must be updated.  For now we assume we have to recompute  $\boldsymbol{\tau}_{ij}$  entirely.  Similarly, if the covariate vectors $\mathbf{s}_{ij}(t)$ depend on $\mathbf{z}$ then we need to recompute those as well prior to computing the likelihood.%More specifically, for a $D_{ij}$ such that $z_i, z_j \in \{a,b\}$, we must add knots $t_m$ for each.

\section{Simulation}

We check our model fitting procedure using a small synthetic data set involving 10 nodes from 2 clusters.  The first cluster has an increased tendency for reciprocity; members of the second cluster have an increased tendency to continue speaking; any contact from the other group instigates discussion within the group.  Then the specification of each covariate vector is $s_{ij}(t) = [r_1(t,i,j), r_3(t,i,j), r_5(t,i,j)]$.  The parameter vectors $\beta_{1,1} = (1,0,0)$,  $\beta_{1,2} = \beta_{2,1} = (0,0,1)$, and $\beta_{1,1} = (0,1,0)$.

Simulation from the model follows the typical racing exponentials idea with a few subtleties.

\begin{enumerate}
\item $t_0 = 0$, all $s_{ij} = 1$
\item For $i = 1, \ldots, N$, draw $z_i \sim \mbox{Categorical}(\theta)$
\item For $m = 1, \ldots, M$:
  \begin{enumerate}
  \item For all $(i,j)$ such that $z_i,z_j \in \{z_{i_{m-1}},z_{j_{m-1}}\}$:
    \begin{enumerate}
    \item Compute $s_{ij}^*$ using events $1$ through $m-1$
    \item Set $\lambda_{ij}^* \leftarrow \exp\{ \beta_{z_i,z_j} s_{ij}^*\}$ 
    \end{enumerate}
  \item Draw $t_m \sim \mbox{Exponential}\left(\sum_{ij} \lambda_{ij}^*\right)$
  \item Draw $(i_m,j_m) \sim \mbox{Categorical}\left(\lambda_{ij}^* / \sum_{ij}\lambda_{ij}^*\right)$
  \item Save $s_{ij}(t_m) \leftarrow s_{ij}^*$
  \item Save $\lambda_{ij}(t_m) \leftarrow \lambda_{ij}^*$
  \end{enumerate}
\end{enumerate}

TODO: Show statistics relevant to these three effects for interactions within each cluster and interactions between the clusters.  This will show that the simulated data are reasonable given the model.

TODO: Show loglikelihood as a function of iteration to confirm it increases.

TODO: Show cluster assignments reasonable: proportion of times true cluster members co-occur.

TODO: Show parameter bias as a function of iteration; perhaps also as a function of the number of events in the dataset.

\section{Model checking and experiments}

\subsection*{Data}

Each of the following data sets are sequences of dyadic events, where each event has a time associated with it, a sender, and a recipient.

\begin{itemize}
\item Classroom:  Perhaps within a couple of the classrooms we can infer subgroups who tend to obey different relational event dynamics.
\item Email: In small organizations there may be groups of people who tend to have a similar style of interaction, and who also share a pattern of interaction with those outside the group or in another group.
\item Citation networks: Perhaps some groups of papers obey some types of rich-get-richer effects more than others.
\item Other
\end{itemize}

\subsection*{Prediction experiment}
TODO: Prediction experiment for the predicting the next event conditioned on the past.  We want to measure recall.  Compare to fitting the relational event model without the blockmodel structure.  Compare to relational event blockmodel without covariates: $$p(y_{ij}) = \exp\{\beta_{z_i,z_j}\} / \sum_{(i',j') \in \mathcal{R}}\exp\{\beta_{z_{i'},z_{j'}}\} $$.
Or more simply, just use $s_{ij}(t) = 1$.

TODO: Need to see how well the time-portion of the model is specified.

\subsection*{Posterior predictive simulations}

\section{Discussion}
Relational event models \cite{Butts2008} require a knot at each observed event, while other approaches \cite{Meek2011} aim to learn the regions where an intensity is constant.

Possible future work could extend the present framework to a mixed-membership model where for each effect there is a latent cluster assignment.  This way a group of nodes might contact high in-degree nodes at a similar rate, though they vary in the degree to which they adhere to reciprocity.

\bibliographystyle{plain}
\bibliography{refs}

\end{document}
